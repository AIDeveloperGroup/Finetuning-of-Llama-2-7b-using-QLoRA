# Finetuning-of-Llama-2-7b-using-QLoRA
- Finetuning Llama-2-7b using QLoRA using TinyStories dataset
- This finetuning was conducted on the free version of Google collab on a T4 GPU with less than 15 Gb VRAM and 12gb RAM thanks to QLora and Parameter-Efficient Fine-Tuning.
-  Link to the model:
-  Link to dataset: 
